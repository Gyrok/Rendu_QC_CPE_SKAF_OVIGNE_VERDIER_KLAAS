{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96jKRTWg2-7E",
        "colab_type": "text"
      },
      "source": [
        "# Notebook Tutoriel sur une utilisation de Tensorflow pour un réseau neuronal quantique\n",
        "\n",
        "### Paul SKAF, Fabien VERDIER, Adrien OVIGNE\n",
        "\n",
        "Ce notebook est notre rendu du projet final, accompagné de notre rapport écrit, visant à expliquer une des utilisations de tensorflow sur un réseau neuronal quantique. \n",
        "\n",
        "On propose ici de récupérer une grande série d'image de \"3\" et de \"6\" et d'utiliser le machine learning pour apprendre au programme à distinguer quels images sont des \"3\" et lesquels sont des \"6\".\n",
        "L'objectif final est de comparer l'efficacité de ce machine learning en utilisant un réseau quantique et un réseau classique.\n",
        "\n",
        "Ce code est trouvable en ligne sur le site de Tensorflow : https://www.tensorflow.org/quantum/tutorials/mnist.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j6331ZSsQGY3"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbCGB3YW8dFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -q tensorflow==2.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ihXxLm8eJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -q tensorflow-quantum cirq==0.7.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hdgMMZEBGqyl"
      },
      "source": [
        "On importe premièrement les différents modules nécéssaire à la réalisation du programme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "enZ300Bflq80",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z25Axft3J6m_",
        "colab_type": "text"
      },
      "source": [
        "## 1. Chargement des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pDUdGxn-ojgy"
      },
      "source": [
        "### 1.1 Chargement des images brutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xZyGXlaKojgz"
      },
      "source": [
        "On utilise Keras pour interagir avec Tensorflow. La bibliothèque Keras permet d'interagir avec les algorithmes de réseaux de neurones profonds et de machine learning. On l'utilise ici pour charger les images depuis la banque de données MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d9OSExvCojg0",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# On redimensionne la plage des images de [0,255] à [0.0,1.0] \n",
        "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
        "\n",
        "print(\"Number of original training examples:\", len(x_train))\n",
        "print(\"Number of original test examples:\", len(x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fZpbygdGojg3"
      },
      "source": [
        "On filtre ici les images qu'on à reçu pour ne garder que les \"3\" et les \"6\".\n",
        "On va également convertir le label \"y\" en booléen : Vrai si c'est un 3 et Faux si c'est un 6 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hOw68cCZojg4",
        "colab": {}
      },
      "source": [
        "def filter_36(x, y):\n",
        "    keep = (y == 3) | (y == 6)\n",
        "    x, y = x[keep], y[keep]\n",
        "    y = y == 3\n",
        "    return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p-XEU8egGL6q",
        "colab": {}
      },
      "source": [
        "x_train, y_train = filter_36(x_train, y_train)\n",
        "x_test, y_test = filter_36(x_test, y_test)\n",
        "\n",
        "print(\"Number of filtered training examples:\", len(x_train))\n",
        "print(\"Number of filtered test examples:\", len(x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3wyiaP0Xojg_"
      },
      "source": [
        "On montre le premier exemple (la première image donc le premier élément dans x_train, associé au premier label y_train)  : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j5STP7MbojhA",
        "colab": {}
      },
      "source": [
        "print(y_train[0])\n",
        "\n",
        "plt.imshow(x_train[0, :, :, 0])\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wNS9sVPQojhC"
      },
      "source": [
        "### 1.2 Redimensionnement des images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fmmtplIFGL6t"
      },
      "source": [
        "Etant donné que chaque Qubit va être associé à un pixel, une image de taille 28x28 est beaucoup trop grande pour un ordinateur quantique. On redimensionne donc en 4x4 pixels pour avoir 16 qubits sur lesquels travailler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbhUdBFWojhE",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
        "x_test_small = tf.image.resize(x_test, (4,4)).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pOMd7zIjGL6x"
      },
      "source": [
        "On remontre la première image redimensionnée : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YIYOtCRIGL6y",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "print(y_train[0])\n",
        "\n",
        "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gGeF1_qtojhK"
      },
      "source": [
        "### 1.3 Suppresion des images contradictoires"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ZLkq2yeojhL"
      },
      "source": [
        "Cette fonction remove_contradicting va supprimer les images qui possèdent deux labels en même temps.\n",
        "On utilise une collection DefaultDict qui appartient à la bibliothèque Collections de python : [Collections Python](https://docs.python.org/2/library/collections.html) pour les gérer.\n",
        "\n",
        "\n",
        "Source : <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> pour la détection des numéros (Section 3.3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LqOPW0C7ojhL",
        "colab": {}
      },
      "source": [
        "def remove_contradicting(xs, ys):\n",
        "    mapping = collections.defaultdict(set)\n",
        "    for x,y in zip(xs,ys):\n",
        "       mapping[tuple(x.flatten())].add(y)\n",
        "    \n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    for x,y in zip(xs, ys):\n",
        "      labels = mapping[tuple(x.flatten())]\n",
        "      if len(labels) == 1:\n",
        "          new_x.append(x)\n",
        "          new_y.append(list(labels)[0])\n",
        "      else:\n",
        "          # On jette les images qui possèdent les deux labels (True et False)\n",
        "          pass\n",
        "    \n",
        "    num_3 = sum(1 for value in mapping.values() if True in value)\n",
        "    num_6 = sum(1 for value in mapping.values() if False in value)\n",
        "    num_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
        "\n",
        "    print(\"Number of unique images:\", len(mapping.values()))\n",
        "    print(\"Number of 3s: \", num_3)\n",
        "    print(\"Number of 6s: \", num_6)\n",
        "    print(\"Number of contradictory images: \", num_both)\n",
        "    print()\n",
        "    print(\"Initial number of examples: \", len(xs))\n",
        "    print(\"Remaining non-contradictory examples: \", len(new_x))\n",
        "    \n",
        "    return np.array(new_x), np.array(new_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VMOiJfz_ojhP"
      },
      "source": [
        "Cette prévention n'est pas effective à 100% et n'empêchera pas à la suite du programme de recevoir tout de même des images contenant 2 labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zpnsAssWojhP",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SlJ5NVaPojhT"
      },
      "source": [
        "### 1.4 Codage des images sous un circuit quantique\n",
        "\n",
        "La première étape est donc d'encoder chaque pixel de l'image avec un Qubit.\n",
        "On fixe un THRESHOLD (seuil) de 0,5. Si la valeur d'un pixel est supérieur au seuil alors on va pouvoir la traiter et la transformer en float."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1z8J7OyDojhV",
        "colab": {}
      },
      "source": [
        "THRESHOLD = 0.5\n",
        "\n",
        "x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
        "x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SlJ5NVaPojhU"
      },
      "source": [
        "Retirer des images contradictoires à ce stade ne nous laissera qu'avec une centaine d'image, car il n'y a plus assez d'information sur les images pour distinguer nettement les 3 ou 6, ce qui n'est pas suffisant pour traiter les données correctement dans la suite du programme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1z8J7OyDojhW",
        "colab": {}
      },
      "source": [
        "_ = remove_contradicting(x_train_bin, y_train_nocon)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oLyxS9KlojhZ"
      },
      "source": [
        "Les qubits qui sont maintenant associés aux pixels dépassant le seuil, sont transformé au travers d'une Porte $X$ ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aOu_3-3ZGL61",
        "colab": {}
      },
      "source": [
        "def convert_to_circuit(image):\n",
        "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
        "    values = np.ndarray.flatten(image)\n",
        "    qubits = cirq.GridQubit.rect(4, 4)\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, value in enumerate(values):\n",
        "        if value:\n",
        "            circuit.append(cirq.X(qubits[i]))\n",
        "    return circuit\n",
        "\n",
        "\n",
        "x_train_circ = [convert_to_circuit(x) for x in x_train_bin]\n",
        "x_test_circ = [convert_to_circuit(x) for x in x_test_bin]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zSCXqzOzojhd"
      },
      "source": [
        "Voilà le circuit associé à la première image affiché dans le haut du programme \n",
        "\n",
        "On remarque que seul 2 pixels dépassent le seuil de 0,5, celui en (2,2) et celui en (3,1), d'où les deux transformations dans le circuit :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w3POmUEUojhe",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "SVGCircuit(x_train_circ[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AEQMxCcBojhg"
      },
      "source": [
        "On compare maintenant numériquement juste pour vérifier où se situe les pixels dépassant le seuil :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TBIsiXdtojhh",
        "colab": {}
      },
      "source": [
        "bin_img = x_train_bin[0,:,:,0]\n",
        "indices = np.array(np.where(bin_img)).T\n",
        "indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mWZ24w1Oojhk"
      },
      "source": [
        "On finit cette partie en convertissant les objets circuits Cirq en tenseur pour TensorFlow : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IZStEMk4ojhk",
        "colab": {}
      },
      "source": [
        "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
        "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4USiqeOqGL67"
      },
      "source": [
        "## 2. Réseau de neurone quantique\n",
        "\n",
        "Il y a très peu de données sur les réseaux de neurones quantiques qui classifient les images. La classification est basé sur le qubit de lecture. <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose un modèle avec un qubit de lecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "knIzawEeojho"
      },
      "source": [
        "### 2.1 Construction du circuit\n",
        "\n",
        "Le circuit est construit à l'aide d'une approche par couche. La classe *CircuitLayerBuiler* permet de créer un circuit et d'y ajouter des couches en ajoutant une porte quantique à tous les qubits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-hjxxgU5ojho",
        "colab": {}
      },
      "source": [
        "class CircuitLayerBuilder():\n",
        "    def __init__(self, data_qubits, readout):\n",
        "        self.data_qubits = data_qubits\n",
        "        self.readout = readout\n",
        "    \n",
        "    def add_layer(self, circuit, gate, prefix):\n",
        "        for i, qubit in enumerate(self.data_qubits):\n",
        "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
        "            circuit.append(gate(qubit, self.readout)**symbol)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sjo5hANFojhr"
      },
      "source": [
        "Voici un exemple de circuit à 4 qubits et un qubit de lecture. Nous affichons le circuit résultant avec la fonction SVGCircuit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SzXWOpUGojhs",
        "colab": {}
      },
      "source": [
        "demo_builder = CircuitLayerBuilder(data_qubits = cirq.GridQubit.rect(4,1),\n",
        "                                   readout=cirq.GridQubit(-1,-1))\n",
        "\n",
        "circuit = cirq.Circuit()\n",
        "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
        "SVGCircuit(circuit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T-QhPE1pojhu"
      },
      "source": [
        "Nous allons maintenant construire un circuit à 2 couches, mais avec 16 qubits, le nombre de pixels de l'image. Les deux couches une couches avec deux portes X et une autre avec deux portes Z."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JiALbpwRGL69",
        "colab": {}
      },
      "source": [
        "def create_quantum_model():\n",
        "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
        "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
        "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
        "    circuit = cirq.Circuit()\n",
        "    \n",
        "    # Prepare the readout qubit.\n",
        "    circuit.append(cirq.X(readout))\n",
        "    circuit.append(cirq.H(readout))\n",
        "    \n",
        "    builder = CircuitLayerBuilder(\n",
        "        data_qubits = data_qubits,\n",
        "        readout=readout)\n",
        "\n",
        "    # Then add layers (experiment by adding more).\n",
        "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
        "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
        "\n",
        "    # Finally, prepare the readout qubit.\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2QZvVh7vojhx",
        "colab": {}
      },
      "source": [
        "model_circuit, model_readout = create_quantum_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LY7vbY6yfABE"
      },
      "source": [
        "### 2.2 Adaptation du circuit à tfq-keras\n",
        "\n",
        "Nous construisons le réseau en empilant les couches avec `tf.keras.Sequential`. L'input n'est pas quantique, mais l'output oui. Avec `tfq.layers.PQC`, on initialise les paramètres et on les gère de manière native avec Keras.\n",
        "\n",
        "Pour classer les images, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose de regarder la valeur de readout qui doit se situer entre -1 et 1. Si cette valeur est inférieur à zéro, alors on a 6, sinon on a 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZYdf_KOxojh0",
        "colab": {}
      },
      "source": [
        "# Build the Keras model.\n",
        "model = tf.keras.Sequential([\n",
        "    # The input is the data-circuit, encoded as a tf.string\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
        "    tfq.layers.PQC(model_circuit, model_readout),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jz-FbVc9ojh3"
      },
      "source": [
        "On décrit ensuite la méthode d'apprentissage avec la fonction `compile`.\n",
        "\n",
        "Nous utilisons `Hinge loss` comme fonction coût. Cette fonction attend des valeurs entre -1 et 1. Donc on fait passer `y_train_hinge` et `y_test_hinge` entre -1 et 1 très simplement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CgMNkC1Fojh5",
        "colab": {}
      },
      "source": [
        "y_train_hinge = 2.0*y_train_nocon-1.0\n",
        "y_test_hinge = 2.0*y_test-1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5nwnveDiojh7"
      },
      "source": [
        "Nous devons ensuite faire notre propre fonction `hinge_accuracy` pour gérer les valeurs entre -1 et 1 car `tf.losses.BinaryAccuracy(threshold=0.0)` attend en entrée un booléen et n'est donc pas utilisable avec la fonction coût hinge loss.\n",
        "\n",
        "Lors de la compilation du modèle, on précise la fonction personnalisée pour la métrique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3XKtZ_TEojh8",
        "colab": {}
      },
      "source": [
        "def hinge_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true) > 0.0\n",
        "    y_pred = tf.squeeze(y_pred) > 0.0\n",
        "    result = tf.cast(y_true == y_pred, tf.float32)\n",
        "\n",
        "    return tf.reduce_mean(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FlpETlLRojiA",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.Hinge(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[hinge_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jkHq2RstojiC",
        "colab": {}
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lsuOzDYblA9s"
      },
      "source": [
        "### Entrainement du circuit quantique\n",
        "\n",
        "Il faut maintenant entrainer le circuit quantique avec le set de données à notre disposition. Le faire avec toutes les données prend beaucoup de temps (3-4h). Pour que ce temps dure moins longtemps, on peut entrainer le modéle circuit sur moins de données (on met `NUM_EXAMPLES=500` ci-dessous par exemple), mais les performances du circuit seront moins bonnes.\n",
        "\n",
        "`EPOCHS` donne le nombre d'itérations sur le set de données, `BATCH_SIZE` le nombre de paramètres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8vuQpSLlBV2",
        "colab": {}
      },
      "source": [
        "EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "NUM_EXAMPLES = len(x_train_tfcirc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qJnNG-3JojiI",
        "colab": {}
      },
      "source": [
        "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
        "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QMSdgGC1GL7D"
      },
      "source": [
        "On arrive à une précision supérieur à 85% en entrainant ce circuit avec toutes les données.\n",
        "On évalue le circuit avec la fonction `evaluate`. `qnn_results[1]` nous donne la précision du circuit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ya9qP3KkojiM",
        "colab": {}
      },
      "source": [
        "qnn_history = model.fit(\n",
        "      x_train_tfcirc_sub, y_train_hinge_sub,\n",
        "      batch_size=32,\n",
        "      epochs=EPOCHS,\n",
        "      verbose=1,\n",
        "      validation_data=(x_test_tfcirc, y_test_hinge))\n",
        "\n",
        "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ER7B7aaojiP"
      },
      "source": [
        "Note: La précision est la moyenne des précisions à chaque itérations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8952YvuWGL7J"
      },
      "source": [
        "## 3. Réseau de Neurone Classique\n",
        "Un réseau de neurone classique peut facilement dépasser un réseau de neurone quantique sur ce genre d'échantillon.\n",
        "Dans l'exemple qui suit, le réseau de neurone classique va traiter les images en entière (28x28 pixels) et va facilement converger vers 100% de précision en peu de temps.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pZofEHhLGL7L",
        "colab": {}
      },
      "source": [
        "def create_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_classical_model()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiAJl7sZojiU",
        "colab": {}
      },
      "source": [
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=128,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "cnn_results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X5-5BVJaojiZ"
      },
      "source": [
        "Le modèle du dessus a presque 1 200 000 paramètres. \n",
        "Pour pouvoir comparer équitablement avec le modèle quantique, on va utiliser un modèle à 37 paramètres :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "70TOM6r-ojiZ",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "def create_fair_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
        "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_fair_classical_model()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lA_Fx-8gojid",
        "colab": {}
      },
      "source": [
        "model.fit(x_train_bin,\n",
        "          y_train_nocon,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test_bin, y_test))\n",
        "\n",
        "fair_nn_results = model.evaluate(x_test_bin, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RH3mam7EGL7N"
      },
      "source": [
        "## 4. Comparaison\n",
        "\n",
        "Une entrée à plus haute résolution et un modèle plus puissant rendent ce problème facile pour un réseau de neurone classique. Alors qu'un modèle classique de puissance similaire (~32 paramètres) s'entraîne avec une précision similaire en une fraction de temps. Le réseau neuronal classique surpasse facilement le réseau neuronal quantique. Pour les données classiques, il est difficile de battre un réseau de neurones classique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NOMeN7pMGL7P",
        "colab": {}
      },
      "source": [
        "qnn_accuracy = qnn_results[1]\n",
        "cnn_accuracy = cnn_results[1]\n",
        "fair_nn_accuracy = fair_nn_results[1]\n",
        "\n",
        "sns.barplot([\"Quantum\", \"Classical, full\", \"Classical, fair\"],\n",
        "            [qnn_accuracy, cnn_accuracy, fair_nn_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "MNIST-classification (1).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}